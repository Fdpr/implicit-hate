{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a088590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext\n",
    "from gensim.test.utils import datapath\n",
    "import pandas as pd\n",
    "from textstat.textstat import *\n",
    "from nltk.sentiment import vader\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e54ea",
   "metadata": {},
   "source": [
    "## Final model assembly\n",
    "The final classifier combines the knowledge from the research and experiments up to now. First, all the features will be collected, including:\n",
    "- Semantic Embeddings\n",
    "- Surface Features\n",
    "- RNSB-Classifier-Score\n",
    "- Sentiment intensity\n",
    "- More features from Davidson (2017)\n",
    "\n",
    "Two classifiers will be created, one for each semantic embedding model (pretrained facebook vectors and the finetuned model). Afterwards, to optimize the classifiers, their performance will be compared and - similar to the first classifier test - the features will be analyzed and the classifier will be optimized using hyperparameter-finetuning. Finally, the end result can be tested on new data to measure its performance across domain, viz. explicit hate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afcb09",
   "metadata": {},
   "source": [
    "### Loading twitter data\n",
    "Same as it ever was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642227bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>class</th>\n",
       "      <th>ID</th>\n",
       "      <th>implicit_class</th>\n",
       "      <th>extra_implicit_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" : jewish harvard professor noel ignatiev w...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>399886440588247041</td>\n",
       "      <td>white_grievance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b.higher education is a part of european cult...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>929901925100937216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has a problem with  \" the whites \" \" and \" \" ...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>728678509497954304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is yasir qadhi a hate preacher for calling ch...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>625688620444180481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt  \" : how three million germans mass murder...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>441089979322597376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20386</th>\n",
       "      <td>Seeing prostitutes is morally wrong, but being...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>SAP_17154</td>\n",
       "      <td>irony</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20387</th>\n",
       "      <td>I wonder how many females I raped today I spen...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>SAP_17179</td>\n",
       "      <td>irony</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20388</th>\n",
       "      <td>Having a criminal record is more attractive to...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>SAP_17314</td>\n",
       "      <td>stereotypical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20389</th>\n",
       "      <td>Another advantage of being a female: getting b...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>SAP_17343</td>\n",
       "      <td>inferiority</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20390</th>\n",
       "      <td>If men are so privileged and women have it so ...</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>SAP_17406</td>\n",
       "      <td>irony</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20391 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post          class  \\\n",
       "0        \" : jewish harvard professor noel ignatiev w...  implicit_hate   \n",
       "1       b.higher education is a part of european cult...       not_hate   \n",
       "2       has a problem with  \" the whites \" \" and \" \" ...       not_hate   \n",
       "3       is yasir qadhi a hate preacher for calling ch...       not_hate   \n",
       "4       rt  \" : how three million germans mass murder...       not_hate   \n",
       "...                                                  ...            ...   \n",
       "20386  Seeing prostitutes is morally wrong, but being...  implicit_hate   \n",
       "20387  I wonder how many females I raped today I spen...  implicit_hate   \n",
       "20388  Having a criminal record is more attractive to...  implicit_hate   \n",
       "20389  Another advantage of being a female: getting b...  implicit_hate   \n",
       "20390  If men are so privileged and women have it so ...  implicit_hate   \n",
       "\n",
       "                       ID   implicit_class extra_implicit_class  \n",
       "0      399886440588247041  white_grievance                  NaN  \n",
       "1      929901925100937216              NaN                  NaN  \n",
       "2      728678509497954304              NaN                  NaN  \n",
       "3      625688620444180481              NaN                  NaN  \n",
       "4      441089979322597376              NaN                  NaN  \n",
       "...                   ...              ...                  ...  \n",
       "20386           SAP_17154            irony                  NaN  \n",
       "20387           SAP_17179            irony                  NaN  \n",
       "20388           SAP_17314    stereotypical                  NaN  \n",
       "20389           SAP_17343      inferiority                  NaN  \n",
       "20390           SAP_17406            irony                  NaN  \n",
       "\n",
       "[20391 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/implicit-hate-corpus/implicit_hate_v1_stg1_posts.tsv\", delimiter=\"\\t\")\n",
    "df_id = pd.read_csv(\"data/implicit-hate-corpus/implicit_hate_v1_stg1.tsv\", delimiter=\"\\t\")\n",
    "df[\"ID\"] = df_id[\"ID\"]\n",
    "df = df[df[\"class\"] != \"explicit_hate\"]\n",
    "df_class = pd.read_csv(\"data/implicit-hate-corpus/implicit_hate_v1_stg2.tsv\", delimiter=\"\\t\")\n",
    "df = pd.merge(df, df_class, on=\"ID\", how=\"left\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93d696",
   "metadata": {},
   "source": [
    "### Loading vector embeddings\n",
    "We will use pretrained facebook vectors and finetuned facebook vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fceb7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_embeddings = fasttext.load_facebook_vectors(datapath(\"C:/Users/flohk/OneDrive/Uni/Projektseminar/data/crawl-300d-2M-subword/crawl-300d-2M-subword.bin\"))\n",
    "finetuned_embeddings = fasttext.FastText.load(datapath(\"C:/Users/flohk/OneDrive/Uni/Projektseminar/data/fasttext-finetune/model150.model\")).wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0112ec",
   "metadata": {},
   "source": [
    "### Loading scorers from RNSB\n",
    "We will use the logistic regression classifiers trained on the weaponized word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ceaa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/RNSB_classifiers/basic_classifier.pkl\", \"rb\") as basic_file:\n",
    "    basic_rnsb = pickle.load(basic_file)[0]\n",
    "with open(\"data/RNSB_classifiers/finetuned_classifier.pkl\", \"rb\") as finetuned_file:\n",
    "    finetuned_rnsb = pickle.load(finetuned_file)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ca962",
   "metadata": {},
   "source": [
    "## Final vectorizer\n",
    "This function works the same as before, but with some additions: Two redundant features were removed and some more were added. The function takes the vector representation and the respective RNSB classifier as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ff392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = vader.SentimentIntensityAnalyzer()\n",
    "tokenizer = TweetTokenizer()\n",
    "stop = stopwords.words(\"English\")\n",
    "caps_tokens = re.compile(r\"\\w+(?:'\\w+)?|[^\\w\\s]\")\n",
    "\n",
    "def vectorize(sent, vectors, rnsb_scorer):\n",
    "    \n",
    "    sent = sent.replace('\"', \"\")\n",
    "    feature_vector = []\n",
    "    \n",
    "    # Fasttext vectors\n",
    "    tokens = [token for token in tokenizer.tokenize(sent) if token not in stop]\n",
    "    vecs = np.zeros(300)\n",
    "    for token in tokens:\n",
    "        vecs += vectors[token]\n",
    "    if len(tokens) != 0:\n",
    "        vecs = vecs / len(tokens)\n",
    "    feature_vector += list(vecs)\n",
    "    \n",
    "    # Punctuation counts marks\n",
    "    puncts = []\n",
    "    puncts.append(sent.count(\".\"))\n",
    "    puncts.append(sent.count(\"...\"))\n",
    "    puncts.append(sent.count(\",\"))\n",
    "    puncts.append(sent.count(\"(\"))\n",
    "    puncts.append(sent.count(\")\"))\n",
    "    puncts.append(sent.count(\":\"))\n",
    "    puncts.append(sent.count(\";\"))\n",
    "    feature_vector += puncts\n",
    "        \n",
    "    # Hashtag count\n",
    "    feature_vector += [sent.count(\"#\")]\n",
    "        \n",
    "    # Is Retweet\n",
    "    retweet = []\n",
    "    if \"b'RT \" in sent or \"bRT \" in sent or \" rt \" in sent:\n",
    "        retweet.append(1)\n",
    "    else:\n",
    "        retweet.append(0)\n",
    "    feature_vector += retweet\n",
    "        \n",
    "    # ratio of words in all caps\n",
    "    filterwords = [token for token in caps_tokens.findall(sent) if token.isalpha() and len(token) > 1]\n",
    "    caps = [word for word in filterwords if word.isupper()]\n",
    "    if len(filterwords) > 0:\n",
    "        ratio = len(caps) / len(filterwords)\n",
    "    else:\n",
    "        ratio = 0\n",
    "    feature_vector += [ratio]\n",
    "    \n",
    "    # hatefulness component scores\n",
    "    hate_scores = []\n",
    "    for token in tokens:\n",
    "        hate_scores.append(rnsb_scorer.predict_proba([vectors[token]])[0,0])\n",
    "    feature_vector += [max(hate_scores), sum(hate_scores)/len(hate_scores)]\n",
    "    \n",
    "    # Sentiment intensity analysis\n",
    "    feature_vector += list(sentiment_analyzer.polarity_scores(sent).values())\n",
    "    \n",
    "    # Features from Davidson\n",
    "    words = \" \".join([token for token in tokens if token.isalpha()])\n",
    "    syllables = textstat.syllable_count(words) \n",
    "    num_chars = sum(len(w) for w in words) \n",
    "    num_chars_total = len(sent)\n",
    "    num_terms = len(sent.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "\n",
    "    feature_vector += [FKRA, FRE, syllables, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms]\n",
    "    \n",
    "    return np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612e10f",
   "metadata": {},
   "source": [
    "### Benchmarking the models\n",
    "Now, let's test what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbe623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_svm(X_svm, embeddings_svm, rnsb_svm, y_svm, svm_params={\"kernel\":\"rbf\", \"C\":100, \"gamma\":0.005}):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    acc, prec, rec = 0, 0, 0\n",
    "    svm = None\n",
    "    for train_index, test_index in kf.split(X_svm):\n",
    "        X_train, X_test = X_svm[train_index], X_svm[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        svm = SVC(**svm_params)\n",
    "        svm.fit(X_train, y_train)\n",
    "        test_labels = svm.predict(X_test)\n",
    "        acc += accuracy_score(y_true=y_test, y_pred=test_labels)\n",
    "        prec += precision_score(y_true=y_test, y_pred=test_labels, zero_division = 0)\n",
    "        rec += recall_score(y_true=y_test, y_pred=test_labels)\n",
    "    return svm, acc/5, prec/5, rec/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3eb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['class'] == \"implicit_hate\")\n",
    "X_basic = StandardScaler().fit_transform(np.array([vectorize(tweet, basic_embeddings, basic_rnsb) for tweet in df[\"post\"]])) \n",
    "X_finetuned = StandardScaler().fit_transform(np.array([vectorize(tweet, finetuned_embeddings, finetuned_rnsb) for tweet in df[\"post\"]]))  \n",
    "\n",
    "basic_svm, basic_acc, basic_prec, basic_rec = train_test_svm(X_basic, basic_embeddings, basic_rnsb, y)\n",
    "print(\"Basic embeddings: accuracy\", basic_acc, \"precision\", basic_prec, \"recall\", basic_rec)\n",
    "finetuned_svm, finetuned_acc, finetuned_prec, finetuned_rec = train_test_svm(X_finetuned, finetuned_embeddings, finetuned_rnsb, y)\n",
    "print(\"Finetuned embeddings: accuracy\", finetuned_acc, \"precision\", finetuned_prec, \"recall\", finetuned_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "53a6dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f15 (precc, recc):\n",
    "    return 4.375 * ((precc * recc) / ((3.375 * precc) + recc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8397887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic: 0.5677792888634975 finetuned: 0.5549277370867924\n"
     ]
    }
   ],
   "source": [
    "print(\"basic:\", f15(basic_prec, basic_rec), \"finetuned:\", f15(finetuned_prec, finetuned_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8f44e",
   "metadata": {},
   "source": [
    "This data suggests two things:\n",
    "1. Because we still value F1.5 over accuracy, it seems like the finetuned word embeddings perform more weakly and are thus not useful for our purposes\n",
    "2. The scores have not significanty improved since the previous iteration of the model. Since most of the added features were taken from the Davidson (2017) classifier where they have proven to be very useful, this may imply that the problem of detecting implicit hate speech might be categorically different from explicit hate speech. Otherwise, we would expect the same features to have positive impact on performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce5d88",
   "metadata": {},
   "source": [
    "### Feature analysis\n",
    "Just to make sure, we will perform the same feature analysis from before to see if there were any changes. We will train the same Decision tree as before and measure its featureimportances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94db8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, r_regression\n",
    "from scipy.stats import variation\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef986a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"embedding \" + str(n) for n in range(300)] + [\"num of \" + p for p in [\".\", \"...\", \",\", \"(\", \")\", \":\", \";\", \"#\"]] + [\"is retweet\", \"CAPS ratio\", \"hatefulness max word\", \"hatefulness average\"] + [\"sentiment \" + p for p in [\"negative\", \"neutral\", \"positive\", \"compound\"]] + [\"FKRA\", \"FRE\", \"syllables\", \"num_chars\", \"num_chars_total\", \"num_terms\", \"num_words\", \"num_unique_terms\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "70f7a8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(min_samples_leaf=10, min_samples_split=24)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(min_samples_leaf= 10, min_samples_split= 24)\n",
    "decision_tree.fit(X_basic, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "69788e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embedding 183</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num of .</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embedding 168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embedding 119</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embedding 110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embedding 95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>embedding 93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embedding 207</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>embedding 210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>embedding 218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>embedding 41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>embedding 264</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embedding 222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>embedding 262</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>embedding 46</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>embedding 249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num of ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num of (</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>embedding 247</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>embedding 5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>embedding 141</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>is retweet</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num of )</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>embedding 139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CAPS ratio</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>embedding 4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>embedding 145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>num of ;</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>embedding 131</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>num of :</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>embedding 224</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>embedding 138</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>embedding 24</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>embedding 74</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>embedding 223</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>embedding 242</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>num of #</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>embedding 163</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>embedding 31</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>embedding 69</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>embedding 278</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>embedding 134</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>embedding 189</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>embedding 88</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sentiment neutral</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>embedding 118</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>embedding 94</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>embedding 72</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>embedding 57</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>embedding 34</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>embedding 10</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>embedding 54</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>embedding 226</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>embedding 132</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>embedding 176</td>\n",
       "      <td>0.000541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>embedding 184</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>num_unique_terms</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>embedding 199</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>embedding 79</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>embedding 114</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>embedding 179</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>FRE</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>embedding 106</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>embedding 13</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>embedding 99</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>embedding 240</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>embedding 298</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>embedding 288</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>embedding 202</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>embedding 250</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>embedding 58</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>embedding 108</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>embedding 216</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>embedding 67</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>embedding 156</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>embedding 127</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>embedding 62</td>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>embedding 6</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>embedding 268</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>embedding 285</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>embedding 271</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>embedding 37</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>embedding 63</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>embedding 170</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>embedding 169</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>embedding 197</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>embedding 297</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>embedding 154</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>embedding 245</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>embedding 192</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>embedding 155</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sentiment positive</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>embedding 215</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>embedding 19</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>embedding 148</td>\n",
       "      <td>0.001104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>embedding 259</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>embedding 96</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>embedding 129</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>embedding 198</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>embedding 296</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>embedding 243</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>embedding 92</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>embedding 165</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>embedding 133</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>embedding 70</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>embedding 295</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>embedding 203</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>embedding 26</td>\n",
       "      <td>0.001245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>embedding 160</td>\n",
       "      <td>0.001251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>embedding 53</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>embedding 159</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>embedding 15</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>embedding 112</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>embedding 190</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>embedding 140</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>embedding 254</td>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>embedding 149</td>\n",
       "      <td>0.001361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>embedding 60</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>embedding 28</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>embedding 261</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>embedding 71</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>embedding 109</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>embedding 281</td>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>hatefulness average</td>\n",
       "      <td>0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>embedding 228</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>embedding 274</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>embedding 66</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>embedding 142</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>embedding 91</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>embedding 43</td>\n",
       "      <td>0.001591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>embedding 196</td>\n",
       "      <td>0.001595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>embedding 126</td>\n",
       "      <td>0.001595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>embedding 205</td>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>embedding 78</td>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>embedding 30</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>embedding 7</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>embedding 44</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>embedding 201</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>embedding 144</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>embedding 103</td>\n",
       "      <td>0.001738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>embedding 80</td>\n",
       "      <td>0.001752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>embedding 113</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>embedding 209</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>embedding 48</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>embedding 269</td>\n",
       "      <td>0.001805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>embedding 143</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>embedding 236</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>embedding 98</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>embedding 0</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>embedding 68</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>embedding 18</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>embedding 273</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>embedding 12</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>embedding 52</td>\n",
       "      <td>0.001928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>embedding 123</td>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>embedding 235</td>\n",
       "      <td>0.001962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>embedding 9</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>embedding 166</td>\n",
       "      <td>0.001983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>embedding 1</td>\n",
       "      <td>0.001983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>sentiment compound</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>embedding 75</td>\n",
       "      <td>0.002013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>embedding 225</td>\n",
       "      <td>0.002022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>embedding 50</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>embedding 100</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>num_terms</td>\n",
       "      <td>0.002043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>embedding 17</td>\n",
       "      <td>0.002091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>embedding 116</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>embedding 191</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>embedding 125</td>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>embedding 186</td>\n",
       "      <td>0.002164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>embedding 299</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>embedding 146</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>embedding 25</td>\n",
       "      <td>0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>embedding 47</td>\n",
       "      <td>0.002203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>embedding 178</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>embedding 237</td>\n",
       "      <td>0.002237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>embedding 211</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>embedding 90</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>embedding 161</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>embedding 2</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>embedding 294</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>embedding 276</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>embedding 272</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>embedding 175</td>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>embedding 121</td>\n",
       "      <td>0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>embedding 251</td>\n",
       "      <td>0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>embedding 252</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>embedding 164</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>embedding 16</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>embedding 124</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>embedding 101</td>\n",
       "      <td>0.002387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>embedding 137</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>embedding 14</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>embedding 188</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>embedding 292</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>embedding 23</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>embedding 171</td>\n",
       "      <td>0.002439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>embedding 231</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>embedding 56</td>\n",
       "      <td>0.002443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>embedding 157</td>\n",
       "      <td>0.002454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>embedding 36</td>\n",
       "      <td>0.002455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>embedding 174</td>\n",
       "      <td>0.002460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>embedding 51</td>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>embedding 208</td>\n",
       "      <td>0.002480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>embedding 81</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>embedding 39</td>\n",
       "      <td>0.002524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>embedding 33</td>\n",
       "      <td>0.002550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>embedding 212</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>embedding 87</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>embedding 181</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>embedding 21</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>embedding 284</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>embedding 253</td>\n",
       "      <td>0.002690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>embedding 233</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>embedding 20</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>embedding 35</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>embedding 172</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>embedding 55</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>embedding 59</td>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>embedding 193</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>FKRA</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>embedding 227</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>embedding 263</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>embedding 122</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>sentiment negative</td>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>embedding 105</td>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>embedding 102</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>embedding 217</td>\n",
       "      <td>0.002852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>embedding 182</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>embedding 204</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>embedding 65</td>\n",
       "      <td>0.002921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>embedding 111</td>\n",
       "      <td>0.002925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>embedding 151</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>embedding 258</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>embedding 238</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>embedding 275</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>embedding 107</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>embedding 84</td>\n",
       "      <td>0.003076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>embedding 45</td>\n",
       "      <td>0.003091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>embedding 153</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>embedding 214</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>embedding 158</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>embedding 206</td>\n",
       "      <td>0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>embedding 265</td>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>embedding 221</td>\n",
       "      <td>0.003295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>embedding 173</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>embedding 49</td>\n",
       "      <td>0.003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>embedding 115</td>\n",
       "      <td>0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>embedding 244</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>embedding 287</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>embedding 86</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>embedding 293</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>embedding 40</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>embedding 291</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>embedding 117</td>\n",
       "      <td>0.003647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>embedding 246</td>\n",
       "      <td>0.003692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>embedding 128</td>\n",
       "      <td>0.003741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>embedding 185</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>syllables</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>embedding 229</td>\n",
       "      <td>0.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>embedding 167</td>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>num_words</td>\n",
       "      <td>0.003926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>embedding 200</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>embedding 232</td>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>embedding 130</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>embedding 230</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>embedding 241</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>embedding 73</td>\n",
       "      <td>0.004065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>embedding 136</td>\n",
       "      <td>0.004077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>embedding 260</td>\n",
       "      <td>0.004131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>num_chars</td>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>embedding 42</td>\n",
       "      <td>0.004177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>embedding 11</td>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>embedding 255</td>\n",
       "      <td>0.004289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>embedding 29</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>embedding 289</td>\n",
       "      <td>0.004512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>embedding 89</td>\n",
       "      <td>0.004578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>embedding 219</td>\n",
       "      <td>0.004580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>embedding 22</td>\n",
       "      <td>0.004583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>embedding 76</td>\n",
       "      <td>0.004696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>embedding 266</td>\n",
       "      <td>0.004696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>embedding 38</td>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>embedding 282</td>\n",
       "      <td>0.004863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>embedding 195</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>embedding 3</td>\n",
       "      <td>0.004905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>embedding 104</td>\n",
       "      <td>0.004938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>embedding 277</td>\n",
       "      <td>0.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>embedding 162</td>\n",
       "      <td>0.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>embedding 270</td>\n",
       "      <td>0.005255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>embedding 152</td>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>embedding 8</td>\n",
       "      <td>0.005564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>embedding 77</td>\n",
       "      <td>0.005713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>embedding 234</td>\n",
       "      <td>0.005727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>hatefulness max word</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>embedding 290</td>\n",
       "      <td>0.005804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>embedding 279</td>\n",
       "      <td>0.005910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>embedding 256</td>\n",
       "      <td>0.005975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>embedding 239</td>\n",
       "      <td>0.006069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>embedding 64</td>\n",
       "      <td>0.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>embedding 82</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>embedding 248</td>\n",
       "      <td>0.006256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>embedding 283</td>\n",
       "      <td>0.006486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>embedding 147</td>\n",
       "      <td>0.006535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>embedding 257</td>\n",
       "      <td>0.006563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>embedding 150</td>\n",
       "      <td>0.006569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>embedding 267</td>\n",
       "      <td>0.006664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>embedding 61</td>\n",
       "      <td>0.006799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>embedding 83</td>\n",
       "      <td>0.007151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>embedding 286</td>\n",
       "      <td>0.007514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>embedding 32</td>\n",
       "      <td>0.007715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>embedding 187</td>\n",
       "      <td>0.007993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>embedding 280</td>\n",
       "      <td>0.008190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>embedding 97</td>\n",
       "      <td>0.008330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>embedding 220</td>\n",
       "      <td>0.010481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>embedding 120</td>\n",
       "      <td>0.010626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>embedding 85</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>embedding 177</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>embedding 180</td>\n",
       "      <td>0.013212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>embedding 213</td>\n",
       "      <td>0.014066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>num_chars_total</td>\n",
       "      <td>0.014613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>embedding 135</td>\n",
       "      <td>0.018015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>embedding 27</td>\n",
       "      <td>0.020211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>embedding 194</td>\n",
       "      <td>0.033538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>num of ,</td>\n",
       "      <td>0.143990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "0           embedding 183    0.000000\n",
       "1                num of .    0.000000\n",
       "2           embedding 168    0.000000\n",
       "3           embedding 119    0.000000\n",
       "4           embedding 110    0.000000\n",
       "5            embedding 95    0.000000\n",
       "6            embedding 93    0.000000\n",
       "7           embedding 207    0.000000\n",
       "8           embedding 210    0.000000\n",
       "9           embedding 218    0.000000\n",
       "10           embedding 41    0.000000\n",
       "11          embedding 264    0.000000\n",
       "12          embedding 222    0.000000\n",
       "13          embedding 262    0.000000\n",
       "14           embedding 46    0.000000\n",
       "15          embedding 249    0.000000\n",
       "16             num of ...    0.000000\n",
       "17               num of (    0.000000\n",
       "18          embedding 247    0.000000\n",
       "19            embedding 5    0.000000\n",
       "20          embedding 141    0.000000\n",
       "21             is retweet    0.000000\n",
       "22               num of )    0.000000\n",
       "23          embedding 139    0.000000\n",
       "24             CAPS ratio    0.000000\n",
       "25            embedding 4    0.000000\n",
       "26          embedding 145    0.000000\n",
       "27               num of ;    0.000000\n",
       "28          embedding 131    0.000000\n",
       "29               num of :    0.000000\n",
       "30          embedding 224    0.000021\n",
       "31          embedding 138    0.000022\n",
       "32           embedding 24    0.000024\n",
       "33           embedding 74    0.000024\n",
       "34          embedding 223    0.000028\n",
       "35          embedding 242    0.000031\n",
       "36               num of #    0.000032\n",
       "37          embedding 163    0.000059\n",
       "38           embedding 31    0.000138\n",
       "39           embedding 69    0.000205\n",
       "40          embedding 278    0.000222\n",
       "41          embedding 134    0.000255\n",
       "42          embedding 189    0.000275\n",
       "43           embedding 88    0.000322\n",
       "44      sentiment neutral    0.000323\n",
       "45          embedding 118    0.000340\n",
       "46           embedding 94    0.000341\n",
       "47           embedding 72    0.000385\n",
       "48           embedding 57    0.000390\n",
       "49           embedding 34    0.000395\n",
       "50           embedding 10    0.000429\n",
       "51           embedding 54    0.000437\n",
       "52          embedding 226    0.000491\n",
       "53          embedding 132    0.000527\n",
       "54          embedding 176    0.000541\n",
       "55          embedding 184    0.000570\n",
       "56       num_unique_terms    0.000617\n",
       "57          embedding 199    0.000619\n",
       "58           embedding 79    0.000692\n",
       "59          embedding 114    0.000697\n",
       "60          embedding 179    0.000713\n",
       "61                    FRE    0.000731\n",
       "62          embedding 106    0.000737\n",
       "63           embedding 13    0.000744\n",
       "64           embedding 99    0.000772\n",
       "65          embedding 240    0.000793\n",
       "66          embedding 298    0.000795\n",
       "67          embedding 288    0.000814\n",
       "68          embedding 202    0.000831\n",
       "69          embedding 250    0.000850\n",
       "70           embedding 58    0.000852\n",
       "71          embedding 108    0.000861\n",
       "72          embedding 216    0.000877\n",
       "73           embedding 67    0.000878\n",
       "74          embedding 156    0.000918\n",
       "75          embedding 127    0.000918\n",
       "76           embedding 62    0.000931\n",
       "77            embedding 6    0.000939\n",
       "78          embedding 268    0.000941\n",
       "79          embedding 285    0.000948\n",
       "80          embedding 271    0.000952\n",
       "81           embedding 37    0.000960\n",
       "82           embedding 63    0.000961\n",
       "83          embedding 170    0.000962\n",
       "84          embedding 169    0.000974\n",
       "85          embedding 197    0.001003\n",
       "86          embedding 297    0.001012\n",
       "87          embedding 154    0.001015\n",
       "88          embedding 245    0.001020\n",
       "89          embedding 192    0.001022\n",
       "90          embedding 155    0.001031\n",
       "91     sentiment positive    0.001037\n",
       "92          embedding 215    0.001090\n",
       "93           embedding 19    0.001090\n",
       "94          embedding 148    0.001104\n",
       "95          embedding 259    0.001112\n",
       "96           embedding 96    0.001120\n",
       "97          embedding 129    0.001127\n",
       "98          embedding 198    0.001131\n",
       "99          embedding 296    0.001135\n",
       "100         embedding 243    0.001135\n",
       "101          embedding 92    0.001143\n",
       "102         embedding 165    0.001158\n",
       "103         embedding 133    0.001159\n",
       "104          embedding 70    0.001175\n",
       "105         embedding 295    0.001189\n",
       "106         embedding 203    0.001215\n",
       "107          embedding 26    0.001245\n",
       "108         embedding 160    0.001251\n",
       "109          embedding 53    0.001262\n",
       "110         embedding 159    0.001275\n",
       "111          embedding 15    0.001292\n",
       "112         embedding 112    0.001299\n",
       "113         embedding 190    0.001324\n",
       "114         embedding 140    0.001335\n",
       "115         embedding 254    0.001343\n",
       "116         embedding 149    0.001361\n",
       "117          embedding 60    0.001372\n",
       "118          embedding 28    0.001433\n",
       "119         embedding 261    0.001468\n",
       "120          embedding 71    0.001471\n",
       "121         embedding 109    0.001482\n",
       "122         embedding 281    0.001489\n",
       "123   hatefulness average    0.001516\n",
       "124         embedding 228    0.001534\n",
       "125         embedding 274    0.001540\n",
       "126          embedding 66    0.001541\n",
       "127         embedding 142    0.001554\n",
       "128          embedding 91    0.001581\n",
       "129          embedding 43    0.001591\n",
       "130         embedding 196    0.001595\n",
       "131         embedding 126    0.001595\n",
       "132         embedding 205    0.001606\n",
       "133          embedding 78    0.001654\n",
       "134          embedding 30    0.001679\n",
       "135           embedding 7    0.001684\n",
       "136          embedding 44    0.001691\n",
       "137         embedding 201    0.001697\n",
       "138         embedding 144    0.001707\n",
       "139         embedding 103    0.001738\n",
       "140          embedding 80    0.001752\n",
       "141         embedding 113    0.001755\n",
       "142         embedding 209    0.001779\n",
       "143          embedding 48    0.001783\n",
       "144         embedding 269    0.001805\n",
       "145         embedding 143    0.001826\n",
       "146         embedding 236    0.001833\n",
       "147          embedding 98    0.001845\n",
       "148           embedding 0    0.001864\n",
       "149          embedding 68    0.001873\n",
       "150          embedding 18    0.001876\n",
       "151         embedding 273    0.001879\n",
       "152          embedding 12    0.001923\n",
       "153          embedding 52    0.001928\n",
       "154         embedding 123    0.001955\n",
       "155         embedding 235    0.001962\n",
       "156           embedding 9    0.001973\n",
       "157         embedding 166    0.001983\n",
       "158           embedding 1    0.001983\n",
       "159    sentiment compound    0.002008\n",
       "160          embedding 75    0.002013\n",
       "161         embedding 225    0.002022\n",
       "162          embedding 50    0.002028\n",
       "163         embedding 100    0.002035\n",
       "164             num_terms    0.002043\n",
       "165          embedding 17    0.002091\n",
       "166         embedding 116    0.002109\n",
       "167         embedding 191    0.002148\n",
       "168         embedding 125    0.002160\n",
       "169         embedding 186    0.002164\n",
       "170         embedding 299    0.002178\n",
       "171         embedding 146    0.002189\n",
       "172          embedding 25    0.002197\n",
       "173          embedding 47    0.002203\n",
       "174         embedding 178    0.002226\n",
       "175         embedding 237    0.002237\n",
       "176         embedding 211    0.002244\n",
       "177          embedding 90    0.002260\n",
       "178         embedding 161    0.002277\n",
       "179           embedding 2    0.002286\n",
       "180         embedding 294    0.002296\n",
       "181         embedding 276    0.002311\n",
       "182         embedding 272    0.002319\n",
       "183         embedding 175    0.002320\n",
       "184         embedding 121    0.002337\n",
       "185         embedding 251    0.002351\n",
       "186         embedding 252    0.002353\n",
       "187         embedding 164    0.002355\n",
       "188          embedding 16    0.002370\n",
       "189         embedding 124    0.002379\n",
       "190         embedding 101    0.002387\n",
       "191         embedding 137    0.002392\n",
       "192          embedding 14    0.002409\n",
       "193         embedding 188    0.002428\n",
       "194         embedding 292    0.002428\n",
       "195          embedding 23    0.002428\n",
       "196         embedding 171    0.002439\n",
       "197         embedding 231    0.002442\n",
       "198          embedding 56    0.002443\n",
       "199         embedding 157    0.002454\n",
       "200          embedding 36    0.002455\n",
       "201         embedding 174    0.002460\n",
       "202          embedding 51    0.002473\n",
       "203         embedding 208    0.002480\n",
       "204          embedding 81    0.002516\n",
       "205          embedding 39    0.002524\n",
       "206          embedding 33    0.002550\n",
       "207         embedding 212    0.002598\n",
       "208          embedding 87    0.002607\n",
       "209         embedding 181    0.002618\n",
       "210          embedding 21    0.002624\n",
       "211         embedding 284    0.002679\n",
       "212         embedding 253    0.002690\n",
       "213         embedding 233    0.002728\n",
       "214          embedding 20    0.002728\n",
       "215          embedding 35    0.002732\n",
       "216         embedding 172    0.002741\n",
       "217          embedding 55    0.002759\n",
       "218          embedding 59    0.002768\n",
       "219         embedding 193    0.002778\n",
       "220                  FKRA    0.002786\n",
       "221         embedding 227    0.002800\n",
       "222         embedding 263    0.002803\n",
       "223         embedding 122    0.002813\n",
       "224    sentiment negative    0.002826\n",
       "225         embedding 105    0.002826\n",
       "226         embedding 102    0.002827\n",
       "227         embedding 217    0.002852\n",
       "228         embedding 182    0.002889\n",
       "229         embedding 204    0.002889\n",
       "230          embedding 65    0.002921\n",
       "231         embedding 111    0.002925\n",
       "232         embedding 151    0.002936\n",
       "233         embedding 258    0.002948\n",
       "234         embedding 238    0.002949\n",
       "235         embedding 275    0.002986\n",
       "236         embedding 107    0.003029\n",
       "237          embedding 84    0.003076\n",
       "238          embedding 45    0.003091\n",
       "239         embedding 153    0.003116\n",
       "240         embedding 214    0.003125\n",
       "241         embedding 158    0.003142\n",
       "242         embedding 206    0.003194\n",
       "243         embedding 265    0.003279\n",
       "244         embedding 221    0.003295\n",
       "245         embedding 173    0.003312\n",
       "246          embedding 49    0.003350\n",
       "247         embedding 115    0.003418\n",
       "248         embedding 244    0.003455\n",
       "249         embedding 287    0.003467\n",
       "250          embedding 86    0.003481\n",
       "251         embedding 293    0.003497\n",
       "252          embedding 40    0.003577\n",
       "253         embedding 291    0.003597\n",
       "254         embedding 117    0.003647\n",
       "255         embedding 246    0.003692\n",
       "256         embedding 128    0.003741\n",
       "257         embedding 185    0.003759\n",
       "258             syllables    0.003787\n",
       "259         embedding 229    0.003842\n",
       "260         embedding 167    0.003920\n",
       "261             num_words    0.003926\n",
       "262         embedding 200    0.003952\n",
       "263         embedding 232    0.003955\n",
       "264         embedding 130    0.003979\n",
       "265         embedding 230    0.003984\n",
       "266         embedding 241    0.003989\n",
       "267          embedding 73    0.004065\n",
       "268         embedding 136    0.004077\n",
       "269         embedding 260    0.004131\n",
       "270             num_chars    0.004162\n",
       "271          embedding 42    0.004177\n",
       "272          embedding 11    0.004275\n",
       "273         embedding 255    0.004289\n",
       "274          embedding 29    0.004411\n",
       "275         embedding 289    0.004512\n",
       "276          embedding 89    0.004578\n",
       "277         embedding 219    0.004580\n",
       "278          embedding 22    0.004583\n",
       "279          embedding 76    0.004696\n",
       "280         embedding 266    0.004696\n",
       "281          embedding 38    0.004801\n",
       "282         embedding 282    0.004863\n",
       "283         embedding 195    0.004900\n",
       "284           embedding 3    0.004905\n",
       "285         embedding 104    0.004938\n",
       "286         embedding 277    0.005172\n",
       "287         embedding 162    0.005224\n",
       "288         embedding 270    0.005255\n",
       "289         embedding 152    0.005561\n",
       "290           embedding 8    0.005564\n",
       "291          embedding 77    0.005713\n",
       "292         embedding 234    0.005727\n",
       "293  hatefulness max word    0.005786\n",
       "294         embedding 290    0.005804\n",
       "295         embedding 279    0.005910\n",
       "296         embedding 256    0.005975\n",
       "297         embedding 239    0.006069\n",
       "298          embedding 64    0.006104\n",
       "299          embedding 82    0.006115\n",
       "300         embedding 248    0.006256\n",
       "301         embedding 283    0.006486\n",
       "302         embedding 147    0.006535\n",
       "303         embedding 257    0.006563\n",
       "304         embedding 150    0.006569\n",
       "305         embedding 267    0.006664\n",
       "306          embedding 61    0.006799\n",
       "307          embedding 83    0.007151\n",
       "308         embedding 286    0.007514\n",
       "309          embedding 32    0.007715\n",
       "310         embedding 187    0.007993\n",
       "311         embedding 280    0.008190\n",
       "312          embedding 97    0.008330\n",
       "313         embedding 220    0.010481\n",
       "314         embedding 120    0.010626\n",
       "315          embedding 85    0.010746\n",
       "316         embedding 177    0.011090\n",
       "317         embedding 180    0.013212\n",
       "318         embedding 213    0.014066\n",
       "319       num_chars_total    0.014613\n",
       "320         embedding 135    0.018015\n",
       "321          embedding 27    0.020211\n",
       "322         embedding 194    0.033538\n",
       "323              num of ,    0.143990"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_importances = pd.DataFrame([[feature_names[f], np.sort(decision_tree.feature_importances_)[i]] for i, f in enumerate(np.argsort(decision_tree.feature_importances_))], columns = [\"feature\", \"importance\"])\n",
    "with pd.option_context('display.min_rows', 324, 'display.max_rows', 324):\n",
    "    display(tree_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff318a",
   "metadata": {},
   "source": [
    "It seems that - at least for the decision tree classifier - some of the new features are actually important. The `num_chars_total` and `hatefulness max word` in particular have an importance of over 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4310f8e",
   "metadata": {},
   "source": [
    "We can also compare relative variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d257f885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embedding 95</td>\n",
       "      <td>0.177056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiment neutral</td>\n",
       "      <td>0.241996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatefulness max word</td>\n",
       "      <td>0.269543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hatefulness average</td>\n",
       "      <td>0.362537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embedding 45</td>\n",
       "      <td>0.397284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_chars_total</td>\n",
       "      <td>0.462009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_unique_terms</td>\n",
       "      <td>0.467181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embedding 119</td>\n",
       "      <td>0.472719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_terms</td>\n",
       "      <td>0.479595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_words</td>\n",
       "      <td>0.490526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>embedding 210</td>\n",
       "      <td>0.492494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num_chars</td>\n",
       "      <td>0.498912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embedding 19</td>\n",
       "      <td>0.520156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>syllables</td>\n",
       "      <td>0.521392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FRE</td>\n",
       "      <td>0.576975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>embedding 82</td>\n",
       "      <td>0.601365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>embedding 133</td>\n",
       "      <td>0.633361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>embedding 255</td>\n",
       "      <td>0.640868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FKRA</td>\n",
       "      <td>0.652005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>embedding 9</td>\n",
       "      <td>0.680256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>embedding 192</td>\n",
       "      <td>0.681712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>embedding 153</td>\n",
       "      <td>0.718333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>embedding 48</td>\n",
       "      <td>0.731836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>embedding 2</td>\n",
       "      <td>0.748667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>embedding 243</td>\n",
       "      <td>0.754303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>embedding 97</td>\n",
       "      <td>0.772367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>embedding 224</td>\n",
       "      <td>0.774927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>embedding 176</td>\n",
       "      <td>0.780234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>embedding 92</td>\n",
       "      <td>0.792412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>embedding 198</td>\n",
       "      <td>0.809777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>embedding 71</td>\n",
       "      <td>0.836105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>embedding 138</td>\n",
       "      <td>0.838423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>embedding 222</td>\n",
       "      <td>0.852880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>embedding 140</td>\n",
       "      <td>0.876535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>embedding 165</td>\n",
       "      <td>0.888491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>embedding 276</td>\n",
       "      <td>0.903464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>embedding 24</td>\n",
       "      <td>0.906460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>embedding 32</td>\n",
       "      <td>0.925995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>embedding 35</td>\n",
       "      <td>0.947644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>embedding 67</td>\n",
       "      <td>0.949486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>embedding 200</td>\n",
       "      <td>0.954524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>embedding 69</td>\n",
       "      <td>0.963963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>embedding 249</td>\n",
       "      <td>1.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>embedding 31</td>\n",
       "      <td>1.006038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>embedding 295</td>\n",
       "      <td>1.007026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>embedding 183</td>\n",
       "      <td>1.012926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>embedding 108</td>\n",
       "      <td>1.017616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>embedding 36</td>\n",
       "      <td>1.037168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>embedding 126</td>\n",
       "      <td>1.041075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>embedding 216</td>\n",
       "      <td>1.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>embedding 129</td>\n",
       "      <td>1.060144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>embedding 103</td>\n",
       "      <td>1.067496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>embedding 123</td>\n",
       "      <td>1.070131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>embedding 116</td>\n",
       "      <td>1.078066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>embedding 238</td>\n",
       "      <td>1.082110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>embedding 219</td>\n",
       "      <td>1.123994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>embedding 122</td>\n",
       "      <td>1.136467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>embedding 107</td>\n",
       "      <td>1.160136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>embedding 152</td>\n",
       "      <td>1.162342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>embedding 286</td>\n",
       "      <td>1.169175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>embedding 144</td>\n",
       "      <td>1.174338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>embedding 88</td>\n",
       "      <td>1.185570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>embedding 257</td>\n",
       "      <td>1.197659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sentiment negative</td>\n",
       "      <td>1.208998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>embedding 235</td>\n",
       "      <td>1.225660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>embedding 14</td>\n",
       "      <td>1.226710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>embedding 141</td>\n",
       "      <td>1.254209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>embedding 61</td>\n",
       "      <td>1.268212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>embedding 261</td>\n",
       "      <td>1.270939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>embedding 264</td>\n",
       "      <td>1.273252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>num of .</td>\n",
       "      <td>1.291168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>embedding 104</td>\n",
       "      <td>1.297018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>embedding 137</td>\n",
       "      <td>1.316989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sentiment positive</td>\n",
       "      <td>1.318040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>embedding 293</td>\n",
       "      <td>1.326064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>embedding 180</td>\n",
       "      <td>1.326976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>embedding 16</td>\n",
       "      <td>1.330697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>embedding 53</td>\n",
       "      <td>1.335630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>embedding 254</td>\n",
       "      <td>1.342838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>embedding 90</td>\n",
       "      <td>1.343853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>embedding 154</td>\n",
       "      <td>1.357314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>embedding 130</td>\n",
       "      <td>1.368791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>embedding 5</td>\n",
       "      <td>1.372462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>embedding 56</td>\n",
       "      <td>1.383677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>embedding 43</td>\n",
       "      <td>1.405898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>embedding 34</td>\n",
       "      <td>1.418179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>embedding 211</td>\n",
       "      <td>1.418938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>embedding 239</td>\n",
       "      <td>1.420225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>embedding 18</td>\n",
       "      <td>1.426537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>embedding 98</td>\n",
       "      <td>1.426918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>embedding 117</td>\n",
       "      <td>1.435043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>embedding 297</td>\n",
       "      <td>1.435476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>embedding 96</td>\n",
       "      <td>1.436411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>embedding 39</td>\n",
       "      <td>1.480131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>embedding 151</td>\n",
       "      <td>1.508292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>embedding 118</td>\n",
       "      <td>1.513624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>embedding 213</td>\n",
       "      <td>1.521960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>embedding 226</td>\n",
       "      <td>1.543495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>embedding 37</td>\n",
       "      <td>1.547774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>embedding 60</td>\n",
       "      <td>1.553144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>embedding 0</td>\n",
       "      <td>1.555905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>embedding 187</td>\n",
       "      <td>1.556777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>embedding 20</td>\n",
       "      <td>1.562080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>embedding 155</td>\n",
       "      <td>1.565849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>embedding 28</td>\n",
       "      <td>1.594215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>embedding 74</td>\n",
       "      <td>1.600193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>embedding 102</td>\n",
       "      <td>1.606717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>embedding 158</td>\n",
       "      <td>1.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>embedding 163</td>\n",
       "      <td>1.676564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>embedding 109</td>\n",
       "      <td>1.676836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>embedding 10</td>\n",
       "      <td>1.680456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>embedding 73</td>\n",
       "      <td>1.686464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>embedding 7</td>\n",
       "      <td>1.690788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>embedding 115</td>\n",
       "      <td>1.691629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>embedding 72</td>\n",
       "      <td>1.695475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>embedding 78</td>\n",
       "      <td>1.715278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>embedding 201</td>\n",
       "      <td>1.750195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>embedding 3</td>\n",
       "      <td>1.762406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>embedding 221</td>\n",
       "      <td>1.769357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>embedding 188</td>\n",
       "      <td>1.772391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>embedding 66</td>\n",
       "      <td>1.806365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>embedding 80</td>\n",
       "      <td>1.810711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>embedding 49</td>\n",
       "      <td>1.816584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>embedding 161</td>\n",
       "      <td>1.848371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>embedding 242</td>\n",
       "      <td>1.857809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>embedding 256</td>\n",
       "      <td>1.871947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>embedding 177</td>\n",
       "      <td>1.882881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>embedding 282</td>\n",
       "      <td>1.911313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>embedding 84</td>\n",
       "      <td>1.925865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>embedding 236</td>\n",
       "      <td>1.930866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>embedding 232</td>\n",
       "      <td>1.932030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>embedding 253</td>\n",
       "      <td>1.942931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>embedding 147</td>\n",
       "      <td>1.945056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>embedding 6</td>\n",
       "      <td>1.952171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>embedding 52</td>\n",
       "      <td>1.975094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>embedding 114</td>\n",
       "      <td>1.976602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>embedding 267</td>\n",
       "      <td>2.019682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>embedding 143</td>\n",
       "      <td>2.027530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>embedding 266</td>\n",
       "      <td>2.041785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>embedding 175</td>\n",
       "      <td>2.106320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>embedding 272</td>\n",
       "      <td>2.111785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>embedding 292</td>\n",
       "      <td>2.119623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>embedding 58</td>\n",
       "      <td>2.184246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>embedding 99</td>\n",
       "      <td>2.221629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>embedding 284</td>\n",
       "      <td>2.241054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>embedding 223</td>\n",
       "      <td>2.242040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>embedding 81</td>\n",
       "      <td>2.246842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>embedding 131</td>\n",
       "      <td>2.262834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>embedding 247</td>\n",
       "      <td>2.284166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>embedding 246</td>\n",
       "      <td>2.285443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>embedding 93</td>\n",
       "      <td>2.315088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>embedding 59</td>\n",
       "      <td>2.318472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>embedding 89</td>\n",
       "      <td>2.322693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>embedding 124</td>\n",
       "      <td>2.344228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>embedding 281</td>\n",
       "      <td>2.347048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>embedding 283</td>\n",
       "      <td>2.360280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>embedding 11</td>\n",
       "      <td>2.388086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>embedding 290</td>\n",
       "      <td>2.391253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>embedding 262</td>\n",
       "      <td>2.412569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>embedding 220</td>\n",
       "      <td>2.437580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>embedding 142</td>\n",
       "      <td>2.440976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>embedding 68</td>\n",
       "      <td>2.453126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>embedding 86</td>\n",
       "      <td>2.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>embedding 149</td>\n",
       "      <td>2.495322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>embedding 204</td>\n",
       "      <td>2.527054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>embedding 101</td>\n",
       "      <td>2.532652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>embedding 87</td>\n",
       "      <td>2.569473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>embedding 12</td>\n",
       "      <td>2.584802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>embedding 217</td>\n",
       "      <td>2.693525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>embedding 296</td>\n",
       "      <td>2.701504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>embedding 278</td>\n",
       "      <td>2.705112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>embedding 162</td>\n",
       "      <td>2.729568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>embedding 173</td>\n",
       "      <td>2.730838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>embedding 171</td>\n",
       "      <td>2.732631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>embedding 231</td>\n",
       "      <td>2.743786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>embedding 199</td>\n",
       "      <td>2.750938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>embedding 13</td>\n",
       "      <td>2.781778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>embedding 252</td>\n",
       "      <td>2.801091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>embedding 30</td>\n",
       "      <td>2.809901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>embedding 85</td>\n",
       "      <td>2.837087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>num of :</td>\n",
       "      <td>2.843167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>embedding 196</td>\n",
       "      <td>2.871418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>embedding 287</td>\n",
       "      <td>2.909013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>num of #</td>\n",
       "      <td>2.914290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>embedding 26</td>\n",
       "      <td>2.919278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>embedding 42</td>\n",
       "      <td>2.925149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>embedding 40</td>\n",
       "      <td>2.939312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>embedding 212</td>\n",
       "      <td>2.977978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>embedding 251</td>\n",
       "      <td>2.980732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>embedding 194</td>\n",
       "      <td>2.992148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>embedding 113</td>\n",
       "      <td>3.013971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>embedding 17</td>\n",
       "      <td>3.049971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>embedding 110</td>\n",
       "      <td>3.063498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>embedding 1</td>\n",
       "      <td>3.124648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>embedding 271</td>\n",
       "      <td>3.129120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>embedding 111</td>\n",
       "      <td>3.134114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>embedding 168</td>\n",
       "      <td>3.138223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>embedding 164</td>\n",
       "      <td>3.210913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>embedding 193</td>\n",
       "      <td>3.247579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>embedding 275</td>\n",
       "      <td>3.298227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>embedding 299</td>\n",
       "      <td>3.323093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>embedding 125</td>\n",
       "      <td>3.343854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>embedding 148</td>\n",
       "      <td>3.410161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>embedding 208</td>\n",
       "      <td>3.434198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>embedding 41</td>\n",
       "      <td>3.437429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>embedding 195</td>\n",
       "      <td>3.471609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>embedding 259</td>\n",
       "      <td>3.473013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>embedding 280</td>\n",
       "      <td>3.486133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>embedding 57</td>\n",
       "      <td>3.593368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>embedding 214</td>\n",
       "      <td>3.689379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>embedding 172</td>\n",
       "      <td>3.718746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>embedding 274</td>\n",
       "      <td>3.746591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>embedding 269</td>\n",
       "      <td>3.801932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>embedding 106</td>\n",
       "      <td>3.860888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>embedding 179</td>\n",
       "      <td>3.914656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>embedding 25</td>\n",
       "      <td>3.925804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>embedding 27</td>\n",
       "      <td>3.942531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>embedding 47</td>\n",
       "      <td>3.971135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>embedding 121</td>\n",
       "      <td>3.978722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>embedding 15</td>\n",
       "      <td>4.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>embedding 191</td>\n",
       "      <td>4.058268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>embedding 46</td>\n",
       "      <td>4.082718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>embedding 51</td>\n",
       "      <td>4.288198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>embedding 263</td>\n",
       "      <td>4.312378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>num of ...</td>\n",
       "      <td>4.339640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>embedding 279</td>\n",
       "      <td>4.400429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>embedding 202</td>\n",
       "      <td>4.490698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>embedding 70</td>\n",
       "      <td>4.597308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>embedding 207</td>\n",
       "      <td>4.604262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>embedding 288</td>\n",
       "      <td>4.656849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>embedding 54</td>\n",
       "      <td>4.683017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>embedding 206</td>\n",
       "      <td>4.745599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>embedding 277</td>\n",
       "      <td>4.746286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>embedding 120</td>\n",
       "      <td>4.757141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>embedding 156</td>\n",
       "      <td>4.798350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>embedding 157</td>\n",
       "      <td>4.844299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>embedding 178</td>\n",
       "      <td>4.938328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>embedding 29</td>\n",
       "      <td>4.945858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>embedding 237</td>\n",
       "      <td>5.020160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>embedding 22</td>\n",
       "      <td>5.105639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>embedding 83</td>\n",
       "      <td>5.151746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>embedding 190</td>\n",
       "      <td>5.202763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>embedding 258</td>\n",
       "      <td>5.226427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>embedding 298</td>\n",
       "      <td>5.261136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>embedding 182</td>\n",
       "      <td>5.316149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>embedding 33</td>\n",
       "      <td>5.377677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>embedding 136</td>\n",
       "      <td>5.531151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>embedding 21</td>\n",
       "      <td>5.537223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>embedding 233</td>\n",
       "      <td>5.566265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>embedding 94</td>\n",
       "      <td>5.580007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>embedding 209</td>\n",
       "      <td>5.598711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>embedding 127</td>\n",
       "      <td>5.674466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>num of ,</td>\n",
       "      <td>5.700733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>embedding 225</td>\n",
       "      <td>5.751781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>embedding 160</td>\n",
       "      <td>5.776540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>embedding 55</td>\n",
       "      <td>5.836069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>embedding 146</td>\n",
       "      <td>5.911669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>sentiment compound</td>\n",
       "      <td>5.919783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>is retweet</td>\n",
       "      <td>5.972810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>embedding 65</td>\n",
       "      <td>5.981381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>embedding 77</td>\n",
       "      <td>6.239285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>num of )</td>\n",
       "      <td>6.582289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>embedding 167</td>\n",
       "      <td>6.661370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>embedding 285</td>\n",
       "      <td>6.675830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>embedding 150</td>\n",
       "      <td>6.791434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>num of (</td>\n",
       "      <td>6.895764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>embedding 63</td>\n",
       "      <td>7.088923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>embedding 170</td>\n",
       "      <td>7.266336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>embedding 4</td>\n",
       "      <td>7.301371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>embedding 44</td>\n",
       "      <td>7.303053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>embedding 265</td>\n",
       "      <td>7.332398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>embedding 62</td>\n",
       "      <td>7.405711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>embedding 234</td>\n",
       "      <td>7.463310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>embedding 244</td>\n",
       "      <td>7.579085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>embedding 185</td>\n",
       "      <td>7.587226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>embedding 230</td>\n",
       "      <td>7.869265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>embedding 227</td>\n",
       "      <td>8.021578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>embedding 218</td>\n",
       "      <td>8.616387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>embedding 135</td>\n",
       "      <td>8.740482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>embedding 197</td>\n",
       "      <td>8.868277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>embedding 76</td>\n",
       "      <td>9.203079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>num of ;</td>\n",
       "      <td>9.243723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>embedding 215</td>\n",
       "      <td>9.574891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>embedding 79</td>\n",
       "      <td>10.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>embedding 145</td>\n",
       "      <td>10.097026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>embedding 270</td>\n",
       "      <td>10.112207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>embedding 159</td>\n",
       "      <td>10.182627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>embedding 105</td>\n",
       "      <td>10.391409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>embedding 240</td>\n",
       "      <td>10.540369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>embedding 181</td>\n",
       "      <td>10.717626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>embedding 64</td>\n",
       "      <td>11.503487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>embedding 186</td>\n",
       "      <td>11.557172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>embedding 132</td>\n",
       "      <td>11.670409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>embedding 248</td>\n",
       "      <td>11.679985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>embedding 273</td>\n",
       "      <td>12.038205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>embedding 260</td>\n",
       "      <td>12.305475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>embedding 23</td>\n",
       "      <td>12.998805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>embedding 189</td>\n",
       "      <td>14.970390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>embedding 205</td>\n",
       "      <td>15.792831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>embedding 203</td>\n",
       "      <td>15.997090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>embedding 8</td>\n",
       "      <td>17.647219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>embedding 228</td>\n",
       "      <td>18.052928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>embedding 112</td>\n",
       "      <td>18.604196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>embedding 229</td>\n",
       "      <td>18.919128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>embedding 289</td>\n",
       "      <td>19.653411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>embedding 174</td>\n",
       "      <td>20.296971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>embedding 169</td>\n",
       "      <td>20.743621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>embedding 50</td>\n",
       "      <td>23.992921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>embedding 166</td>\n",
       "      <td>25.115616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>embedding 134</td>\n",
       "      <td>26.086503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>embedding 291</td>\n",
       "      <td>28.013132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>embedding 250</td>\n",
       "      <td>28.051115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>CAPS ratio</td>\n",
       "      <td>30.208063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>embedding 128</td>\n",
       "      <td>30.442286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>embedding 241</td>\n",
       "      <td>33.396430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>embedding 38</td>\n",
       "      <td>38.457835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>embedding 139</td>\n",
       "      <td>40.856432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>embedding 75</td>\n",
       "      <td>58.298150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>embedding 294</td>\n",
       "      <td>61.330074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>embedding 184</td>\n",
       "      <td>66.413147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>embedding 268</td>\n",
       "      <td>92.443681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>embedding 100</td>\n",
       "      <td>104.677536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>embedding 245</td>\n",
       "      <td>160.606334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>embedding 91</td>\n",
       "      <td>169.694622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature    variance\n",
       "0            embedding 95    0.177056\n",
       "1       sentiment neutral    0.241996\n",
       "2    hatefulness max word    0.269543\n",
       "3     hatefulness average    0.362537\n",
       "4            embedding 45    0.397284\n",
       "5         num_chars_total    0.462009\n",
       "6        num_unique_terms    0.467181\n",
       "7           embedding 119    0.472719\n",
       "8               num_terms    0.479595\n",
       "9               num_words    0.490526\n",
       "10          embedding 210    0.492494\n",
       "11              num_chars    0.498912\n",
       "12           embedding 19    0.520156\n",
       "13              syllables    0.521392\n",
       "14                    FRE    0.576975\n",
       "15           embedding 82    0.601365\n",
       "16          embedding 133    0.633361\n",
       "17          embedding 255    0.640868\n",
       "18                   FKRA    0.652005\n",
       "19            embedding 9    0.680256\n",
       "20          embedding 192    0.681712\n",
       "21          embedding 153    0.718333\n",
       "22           embedding 48    0.731836\n",
       "23            embedding 2    0.748667\n",
       "24          embedding 243    0.754303\n",
       "25           embedding 97    0.772367\n",
       "26          embedding 224    0.774927\n",
       "27          embedding 176    0.780234\n",
       "28           embedding 92    0.792412\n",
       "29          embedding 198    0.809777\n",
       "30           embedding 71    0.836105\n",
       "31          embedding 138    0.838423\n",
       "32          embedding 222    0.852880\n",
       "33          embedding 140    0.876535\n",
       "34          embedding 165    0.888491\n",
       "35          embedding 276    0.903464\n",
       "36           embedding 24    0.906460\n",
       "37           embedding 32    0.925995\n",
       "38           embedding 35    0.947644\n",
       "39           embedding 67    0.949486\n",
       "40          embedding 200    0.954524\n",
       "41           embedding 69    0.963963\n",
       "42          embedding 249    1.003208\n",
       "43           embedding 31    1.006038\n",
       "44          embedding 295    1.007026\n",
       "45          embedding 183    1.012926\n",
       "46          embedding 108    1.017616\n",
       "47           embedding 36    1.037168\n",
       "48          embedding 126    1.041075\n",
       "49          embedding 216    1.051842\n",
       "50          embedding 129    1.060144\n",
       "51          embedding 103    1.067496\n",
       "52          embedding 123    1.070131\n",
       "53          embedding 116    1.078066\n",
       "54          embedding 238    1.082110\n",
       "55          embedding 219    1.123994\n",
       "56          embedding 122    1.136467\n",
       "57          embedding 107    1.160136\n",
       "58          embedding 152    1.162342\n",
       "59          embedding 286    1.169175\n",
       "60          embedding 144    1.174338\n",
       "61           embedding 88    1.185570\n",
       "62          embedding 257    1.197659\n",
       "63     sentiment negative    1.208998\n",
       "64          embedding 235    1.225660\n",
       "65           embedding 14    1.226710\n",
       "66          embedding 141    1.254209\n",
       "67           embedding 61    1.268212\n",
       "68          embedding 261    1.270939\n",
       "69          embedding 264    1.273252\n",
       "70               num of .    1.291168\n",
       "71          embedding 104    1.297018\n",
       "72          embedding 137    1.316989\n",
       "73     sentiment positive    1.318040\n",
       "74          embedding 293    1.326064\n",
       "75          embedding 180    1.326976\n",
       "76           embedding 16    1.330697\n",
       "77           embedding 53    1.335630\n",
       "78          embedding 254    1.342838\n",
       "79           embedding 90    1.343853\n",
       "80          embedding 154    1.357314\n",
       "81          embedding 130    1.368791\n",
       "82            embedding 5    1.372462\n",
       "83           embedding 56    1.383677\n",
       "84           embedding 43    1.405898\n",
       "85           embedding 34    1.418179\n",
       "86          embedding 211    1.418938\n",
       "87          embedding 239    1.420225\n",
       "88           embedding 18    1.426537\n",
       "89           embedding 98    1.426918\n",
       "90          embedding 117    1.435043\n",
       "91          embedding 297    1.435476\n",
       "92           embedding 96    1.436411\n",
       "93           embedding 39    1.480131\n",
       "94          embedding 151    1.508292\n",
       "95          embedding 118    1.513624\n",
       "96          embedding 213    1.521960\n",
       "97          embedding 226    1.543495\n",
       "98           embedding 37    1.547774\n",
       "99           embedding 60    1.553144\n",
       "100           embedding 0    1.555905\n",
       "101         embedding 187    1.556777\n",
       "102          embedding 20    1.562080\n",
       "103         embedding 155    1.565849\n",
       "104          embedding 28    1.594215\n",
       "105          embedding 74    1.600193\n",
       "106         embedding 102    1.606717\n",
       "107         embedding 158    1.618182\n",
       "108         embedding 163    1.676564\n",
       "109         embedding 109    1.676836\n",
       "110          embedding 10    1.680456\n",
       "111          embedding 73    1.686464\n",
       "112           embedding 7    1.690788\n",
       "113         embedding 115    1.691629\n",
       "114          embedding 72    1.695475\n",
       "115          embedding 78    1.715278\n",
       "116         embedding 201    1.750195\n",
       "117           embedding 3    1.762406\n",
       "118         embedding 221    1.769357\n",
       "119         embedding 188    1.772391\n",
       "120          embedding 66    1.806365\n",
       "121          embedding 80    1.810711\n",
       "122          embedding 49    1.816584\n",
       "123         embedding 161    1.848371\n",
       "124         embedding 242    1.857809\n",
       "125         embedding 256    1.871947\n",
       "126         embedding 177    1.882881\n",
       "127         embedding 282    1.911313\n",
       "128          embedding 84    1.925865\n",
       "129         embedding 236    1.930866\n",
       "130         embedding 232    1.932030\n",
       "131         embedding 253    1.942931\n",
       "132         embedding 147    1.945056\n",
       "133           embedding 6    1.952171\n",
       "134          embedding 52    1.975094\n",
       "135         embedding 114    1.976602\n",
       "136         embedding 267    2.019682\n",
       "137         embedding 143    2.027530\n",
       "138         embedding 266    2.041785\n",
       "139         embedding 175    2.106320\n",
       "140         embedding 272    2.111785\n",
       "141         embedding 292    2.119623\n",
       "142          embedding 58    2.184246\n",
       "143          embedding 99    2.221629\n",
       "144         embedding 284    2.241054\n",
       "145         embedding 223    2.242040\n",
       "146          embedding 81    2.246842\n",
       "147         embedding 131    2.262834\n",
       "148         embedding 247    2.284166\n",
       "149         embedding 246    2.285443\n",
       "150          embedding 93    2.315088\n",
       "151          embedding 59    2.318472\n",
       "152          embedding 89    2.322693\n",
       "153         embedding 124    2.344228\n",
       "154         embedding 281    2.347048\n",
       "155         embedding 283    2.360280\n",
       "156          embedding 11    2.388086\n",
       "157         embedding 290    2.391253\n",
       "158         embedding 262    2.412569\n",
       "159         embedding 220    2.437580\n",
       "160         embedding 142    2.440976\n",
       "161          embedding 68    2.453126\n",
       "162          embedding 86    2.468800\n",
       "163         embedding 149    2.495322\n",
       "164         embedding 204    2.527054\n",
       "165         embedding 101    2.532652\n",
       "166          embedding 87    2.569473\n",
       "167          embedding 12    2.584802\n",
       "168         embedding 217    2.693525\n",
       "169         embedding 296    2.701504\n",
       "170         embedding 278    2.705112\n",
       "171         embedding 162    2.729568\n",
       "172         embedding 173    2.730838\n",
       "173         embedding 171    2.732631\n",
       "174         embedding 231    2.743786\n",
       "175         embedding 199    2.750938\n",
       "176          embedding 13    2.781778\n",
       "177         embedding 252    2.801091\n",
       "178          embedding 30    2.809901\n",
       "179          embedding 85    2.837087\n",
       "180              num of :    2.843167\n",
       "181         embedding 196    2.871418\n",
       "182         embedding 287    2.909013\n",
       "183              num of #    2.914290\n",
       "184          embedding 26    2.919278\n",
       "185          embedding 42    2.925149\n",
       "186          embedding 40    2.939312\n",
       "187         embedding 212    2.977978\n",
       "188         embedding 251    2.980732\n",
       "189         embedding 194    2.992148\n",
       "190         embedding 113    3.013971\n",
       "191          embedding 17    3.049971\n",
       "192         embedding 110    3.063498\n",
       "193           embedding 1    3.124648\n",
       "194         embedding 271    3.129120\n",
       "195         embedding 111    3.134114\n",
       "196         embedding 168    3.138223\n",
       "197         embedding 164    3.210913\n",
       "198         embedding 193    3.247579\n",
       "199         embedding 275    3.298227\n",
       "200         embedding 299    3.323093\n",
       "201         embedding 125    3.343854\n",
       "202         embedding 148    3.410161\n",
       "203         embedding 208    3.434198\n",
       "204          embedding 41    3.437429\n",
       "205         embedding 195    3.471609\n",
       "206         embedding 259    3.473013\n",
       "207         embedding 280    3.486133\n",
       "208          embedding 57    3.593368\n",
       "209         embedding 214    3.689379\n",
       "210         embedding 172    3.718746\n",
       "211         embedding 274    3.746591\n",
       "212         embedding 269    3.801932\n",
       "213         embedding 106    3.860888\n",
       "214         embedding 179    3.914656\n",
       "215          embedding 25    3.925804\n",
       "216          embedding 27    3.942531\n",
       "217          embedding 47    3.971135\n",
       "218         embedding 121    3.978722\n",
       "219          embedding 15    4.007129\n",
       "220         embedding 191    4.058268\n",
       "221          embedding 46    4.082718\n",
       "222          embedding 51    4.288198\n",
       "223         embedding 263    4.312378\n",
       "224            num of ...    4.339640\n",
       "225         embedding 279    4.400429\n",
       "226         embedding 202    4.490698\n",
       "227          embedding 70    4.597308\n",
       "228         embedding 207    4.604262\n",
       "229         embedding 288    4.656849\n",
       "230          embedding 54    4.683017\n",
       "231         embedding 206    4.745599\n",
       "232         embedding 277    4.746286\n",
       "233         embedding 120    4.757141\n",
       "234         embedding 156    4.798350\n",
       "235         embedding 157    4.844299\n",
       "236         embedding 178    4.938328\n",
       "237          embedding 29    4.945858\n",
       "238         embedding 237    5.020160\n",
       "239          embedding 22    5.105639\n",
       "240          embedding 83    5.151746\n",
       "241         embedding 190    5.202763\n",
       "242         embedding 258    5.226427\n",
       "243         embedding 298    5.261136\n",
       "244         embedding 182    5.316149\n",
       "245          embedding 33    5.377677\n",
       "246         embedding 136    5.531151\n",
       "247          embedding 21    5.537223\n",
       "248         embedding 233    5.566265\n",
       "249          embedding 94    5.580007\n",
       "250         embedding 209    5.598711\n",
       "251         embedding 127    5.674466\n",
       "252              num of ,    5.700733\n",
       "253         embedding 225    5.751781\n",
       "254         embedding 160    5.776540\n",
       "255          embedding 55    5.836069\n",
       "256         embedding 146    5.911669\n",
       "257    sentiment compound    5.919783\n",
       "258            is retweet    5.972810\n",
       "259          embedding 65    5.981381\n",
       "260          embedding 77    6.239285\n",
       "261              num of )    6.582289\n",
       "262         embedding 167    6.661370\n",
       "263         embedding 285    6.675830\n",
       "264         embedding 150    6.791434\n",
       "265              num of (    6.895764\n",
       "266          embedding 63    7.088923\n",
       "267         embedding 170    7.266336\n",
       "268           embedding 4    7.301371\n",
       "269          embedding 44    7.303053\n",
       "270         embedding 265    7.332398\n",
       "271          embedding 62    7.405711\n",
       "272         embedding 234    7.463310\n",
       "273         embedding 244    7.579085\n",
       "274         embedding 185    7.587226\n",
       "275         embedding 230    7.869265\n",
       "276         embedding 227    8.021578\n",
       "277         embedding 218    8.616387\n",
       "278         embedding 135    8.740482\n",
       "279         embedding 197    8.868277\n",
       "280          embedding 76    9.203079\n",
       "281              num of ;    9.243723\n",
       "282         embedding 215    9.574891\n",
       "283          embedding 79   10.018986\n",
       "284         embedding 145   10.097026\n",
       "285         embedding 270   10.112207\n",
       "286         embedding 159   10.182627\n",
       "287         embedding 105   10.391409\n",
       "288         embedding 240   10.540369\n",
       "289         embedding 181   10.717626\n",
       "290          embedding 64   11.503487\n",
       "291         embedding 186   11.557172\n",
       "292         embedding 132   11.670409\n",
       "293         embedding 248   11.679985\n",
       "294         embedding 273   12.038205\n",
       "295         embedding 260   12.305475\n",
       "296          embedding 23   12.998805\n",
       "297         embedding 189   14.970390\n",
       "298         embedding 205   15.792831\n",
       "299         embedding 203   15.997090\n",
       "300           embedding 8   17.647219\n",
       "301         embedding 228   18.052928\n",
       "302         embedding 112   18.604196\n",
       "303         embedding 229   18.919128\n",
       "304         embedding 289   19.653411\n",
       "305         embedding 174   20.296971\n",
       "306         embedding 169   20.743621\n",
       "307          embedding 50   23.992921\n",
       "308         embedding 166   25.115616\n",
       "309         embedding 134   26.086503\n",
       "310         embedding 291   28.013132\n",
       "311         embedding 250   28.051115\n",
       "312            CAPS ratio   30.208063\n",
       "313         embedding 128   30.442286\n",
       "314         embedding 241   33.396430\n",
       "315          embedding 38   38.457835\n",
       "316         embedding 139   40.856432\n",
       "317          embedding 75   58.298150\n",
       "318         embedding 294   61.330074\n",
       "319         embedding 184   66.413147\n",
       "320         embedding 268   92.443681\n",
       "321         embedding 100  104.677536\n",
       "322         embedding 245  160.606334\n",
       "323          embedding 91  169.694622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_features = np.array([vectorize(tweet, basic_embeddings, basic_rnsb) for tweet in df[\"post\"]])\n",
    "feature_variances = pd.DataFrame([[feature_names[f], np.sort(np.abs(variation(analysis_features, axis=0)))[i]] for i, f in enumerate(np.argsort(np.abs(variation(analysis_features, axis=0))))], columns = [\"feature\", \"variance\"])\n",
    "with pd.option_context('display.min_rows', 324, 'display.max_rows', 324):\n",
    "    display(feature_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b79633",
   "metadata": {},
   "source": [
    "The coefficient of variation is highest in the embedding vectors. Most non-semantic features don't have a lot of variation. Especially the hatefulness ratings very only slighty. This is however interesting because the `hatefulness max word` score is quite important to the Decision tree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "316609b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(facecolor=\"xkcd:mint\")\n",
    "pyplot.bar(range(300), np.abs(variation(analysis_features, axis=0))[:300])\n",
    "pyplot.title(\"Semantic embeddings variances\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "359ee0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding 4\n",
      "embedding 6\n",
      "embedding 7\n",
      "embedding 10\n",
      "embedding 11\n",
      "embedding 16\n",
      "embedding 20\n",
      "embedding 22\n",
      "embedding 23\n",
      "embedding 30\n",
      "embedding 38\n",
      "embedding 45\n",
      "embedding 51\n",
      "embedding 52\n",
      "embedding 60\n",
      "embedding 61\n",
      "embedding 63\n",
      "embedding 64\n",
      "embedding 69\n",
      "embedding 70\n",
      "embedding 75\n",
      "embedding 77\n",
      "embedding 78\n",
      "embedding 81\n",
      "embedding 82\n",
      "embedding 86\n",
      "embedding 88\n",
      "embedding 114\n",
      "embedding 119\n",
      "embedding 121\n",
      "embedding 128\n",
      "embedding 135\n",
      "embedding 136\n",
      "embedding 142\n",
      "embedding 144\n",
      "embedding 151\n",
      "embedding 155\n",
      "embedding 157\n",
      "embedding 162\n",
      "embedding 163\n",
      "embedding 164\n",
      "embedding 165\n",
      "embedding 166\n",
      "embedding 176\n",
      "embedding 192\n",
      "embedding 194\n",
      "embedding 202\n",
      "embedding 206\n",
      "embedding 210\n",
      "embedding 213\n",
      "embedding 214\n",
      "embedding 220\n",
      "embedding 224\n",
      "embedding 227\n",
      "embedding 231\n",
      "embedding 236\n",
      "embedding 240\n",
      "embedding 241\n",
      "embedding 242\n",
      "embedding 246\n",
      "embedding 254\n",
      "embedding 255\n",
      "embedding 256\n",
      "embedding 261\n",
      "embedding 266\n",
      "embedding 272\n",
      "embedding 275\n",
      "embedding 276\n",
      "embedding 282\n",
      "embedding 294\n",
      "embedding 296\n",
      "embedding 297\n",
      "embedding 298\n"
     ]
    }
   ],
   "source": [
    "k_best = SelectKBest(r_regression, k=250)\n",
    "k_best.fit(analysis_features, y)\n",
    "k_best_removed = k_best.get_support()\n",
    "_ = [print(feature_names[i]) for i in range(312) if k_best_removed[i] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f590d11",
   "metadata": {},
   "source": [
    "When analyzing the feature space using Pearson correlation, it seems like the additional features are at least somewhat useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76b2b4",
   "metadata": {},
   "source": [
    "With everything taken into consideration, we won't strip these new features from the classifier. Despite not yielding much improvement to the classifier's scores, they seem to be useful according to Decision tree importance and feature analysis. So, no adjustment to the feature space is neccessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80aff7a",
   "metadata": {},
   "source": [
    "### Finetuning the SVM\n",
    "Finally, we can perform one last grid-search to finetune the hyperparameters. Since it is unlikely that a lot has changed since the last iteration, we can limit the search to a small range so that we don't need to scan a huge area which will speed up the grid search considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8fe75abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6d8191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [50, 75, 100, 250, 500],\n",
       "                         'gamma': [0.01, 0.0075, 0.005, 0.001]},\n",
       "             scoring=make_scorer(fbeta_score, beta=1.5), verbose=3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f15 = make_scorer(fbeta_score, beta=1.5)\n",
    "grid_svm = {\"C\": [50, 75, 100, 250, 500],\n",
    "            \"gamma\": [0.01, 0.0075, 0.005, 0.001]}\n",
    "searcher_svm = GridSearchCV(SVC(kernel=\"rbf\"), grid_svm, cv = 3, n_jobs = -1, refit = True, scoring = f15, verbose = 3)\n",
    "searcher_svm.fit(X_basic, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "990d821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4253184115251834"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "479ef1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 250, 'gamma': 0.001}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svm, f_acc, f_prec, f_rec = train_test_svm(X_basic, basic_embeddings, basic_rnsb, y, svm_params={'C':250, 'gamma':0.001, 'kernel':\"rbf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "77956840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter finetuning: accuracy 0.722230599894362 precision 0.60524438314769 recall 0.5818535835692188\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter finetuning: accuracy\", f_acc, \"precision\", f_prec, \"recall\", f_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "302d42b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587039235603636\n"
     ]
    }
   ],
   "source": [
    "print(f15(f_prec, f_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de78aa0",
   "metadata": {},
   "source": [
    "By using an f1.5 scorer, the classifier lost a bit of accuracy and precision, however that evened out the scores. Since in the end, both precision and recall are more or less equally important for this kind of task, having the scores more aligned and equal seems like a positive. Having these parameters finalized, the classifier is built. We can now train an SVM over the whole dataset and that will be the final \"product\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84900b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_hate_classifier = SVC(kernel=\"rbf\", C=250, gamma =0.001)\n",
    "implicit_hate_classifier.fit(X_basic, y)\n",
    "with open(\"implicit_hate_classifier/implicit_hate_classifier.pkl\", \"wb\") as file:\n",
    "    pickle.dump(implicit_hate_classifier, file)\n",
    "scaler = StandardScaler().fit(np.array([vectorize(tweet, basic_embeddings, basic_rnsb) for tweet in df[\"post\"]])) \n",
    "with open(\"implicit_hate_classifier/scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "with open(\"implicit_hate_classifier/vectorize.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorize, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45aa912",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"implicit_hate_classifier/vectorize.pkl\", \"wb\") as file:\n",
    "    dill.dump(vectorize, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c21680",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"implicit_hate_classifier/implicit_hate_classifier.pkl\", \"rb\") as file:\n",
    "    implicit_hate_classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5d905",
   "metadata": {},
   "source": [
    "## Testing the classifier out of domain\n",
    "Finally, we will test how well the classifier performs on other data. We will look at two cases:\n",
    "1. Another dataset which considers mainly implicit hate\n",
    "2. General hatefulness classification\n",
    "\n",
    "Of course, it only makes sense to perform similar data. Because our classifier was trained on social media posts (aka short texts), we should look toward other social media corpora for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72c396",
   "metadata": {},
   "source": [
    "#### I feel offended, don't be abusive\n",
    "Sadly, after requesting access to the data from https://github.com/tommasoc80/AbuseEval, I have yet to receive a reply. So I cannot test on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44804f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e329c877",
   "metadata": {},
   "source": [
    "#### Automatic Hate speech detection and the problem of offensive language\n",
    "The other data comes from https://github.com/t-davidson/hate-speech-and-offensive-language. This dataset contains tweets that are classified to be either hateful, abusive or neither and it mostly concerns explicit hatefulness. Since the data is multiclass which our model can't deal with, we remove the class with offensive tweets. In order to test this data, there are two possibilities:\n",
    "1. Use our current final classifier to predict the class for this data\n",
    "2. Retrain the classifier on this data and see how well it performs\n",
    "\n",
    "We will only perform the first option because it is more relevant to the research question (and also because we implemented a lot of the features from this paper into our model, so retraining on this data would really only be interesting regarding the performance difference from an SVM used here to a logistic regression classifier used there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313d0196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24767</th>\n",
       "      <td>25280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you know what they say, the early bird gets th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>25289</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you're all niggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24777</th>\n",
       "      <td>25290</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you're such a retard i hope you get type 2 dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5593 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      0   \n",
       "40             40      3            0                   1        2      0   \n",
       "63             63      3            0                   0        3      0   \n",
       "66             66      3            0                   1        2      0   \n",
       "67             67      3            0                   1        2      0   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24767       25280      3            0                   1        2      0   \n",
       "24776       25289      3            3                   0        0      1   \n",
       "24777       25290      3            2                   1        0      1   \n",
       "24779       25292      3            0                   1        2      0   \n",
       "24782       25296      3            0                   0        3      0   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "40       \" momma said no pussy cats inside my doghouse \"  \n",
       "63     \"@Addicted2Guys: -SimplyAddictedToGuys http://...  \n",
       "66     \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...  \n",
       "67     \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...  \n",
       "...                                                  ...  \n",
       "24767  you know what they say, the early bird gets th...  \n",
       "24776                                 you're all niggers  \n",
       "24777  you're such a retard i hope you get type 2 dia...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[5593 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdavid = pd.read_csv(\"data/davidson/labeled_data.csv\")\n",
    "dfdavid = dfdavid[dfdavid[\"class\"] != 1]\n",
    "dfdavid[\"class\"] = np.asarray(dfdavid[\"class\"] == 0, dtype=int)\n",
    "# dfdavid.iloc[np.asarray(dfdavid[\"hate_speech\"] == 3)]\n",
    "dfdavid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a416fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4163, 1: 1430})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(dfdavid[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5693d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_david = StandardScaler().fit_transform(np.array([vectorize(tweet, basic_embeddings, basic_rnsb) for tweet in dfdavid[\"tweet\"]])) \n",
    "y_david = np.array(dfdavid['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7b954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_david_pred = implicit_hate_classifier.predict(X_david)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861629d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.49347398533881637 precision: 0.26671100764881944 recall: 0.5608391608391609\n"
     ]
    }
   ],
   "source": [
    "acc_david = accuracy_score(y_true=y_david, y_pred=y_david_pred)\n",
    "prec_david = precision_score(y_true=y_david, y_pred=y_david_pred, zero_division = 0)\n",
    "rec_david = recall_score(y_true=y_david, y_pred=y_david_pred)\n",
    "print(\"accuracy:\", acc_david, \"precision:\", prec_david, \"recall:\", rec_david)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0586e",
   "metadata": {},
   "source": [
    "Accuracy and recall don't seem to bad, but the precision is terrible. Let's compare to a random baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb2a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.507777579116753 precision: 0.25901639344262295 recall: 0.4972027972027972\n"
     ]
    }
   ],
   "source": [
    "y_david_random = np.asarray(np.random.rand(5593) >= 0.5, dtype=int)\n",
    "acc_david_r = accuracy_score(y_true=y_david, y_pred=y_david_random)\n",
    "prec_david_r = precision_score(y_true=y_david, y_pred=y_david_random, zero_division = 0)\n",
    "rec_david_r = recall_score(y_true=y_david, y_pred=y_david_random)\n",
    "print(\"accuracy:\", acc_david_r, \"precision:\", prec_david_r, \"recall:\", rec_david_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d38369",
   "metadata": {},
   "source": [
    "We can see that it is hardly better than random chance. Thus, we can draw the tentative conclusion that the task of implicit hate speech classification is sufficiently detached from explicit (or general) hate speech classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
